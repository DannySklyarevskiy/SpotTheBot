{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e63912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    set_seed,\n",
    ")\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a2313fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config (v1 baseline)\n",
    "\n",
    "CSV_PATH = \"bot_detection_data.csv\"   \n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "MAX_LEN = 128\n",
    "SEED = 42\n",
    "\n",
    "# Try likely column names first (we'll auto-detect)\n",
    "TEXT_COL_CANDIDATES = [\"text\", \"tweet\", \"status\", \"content\"]\n",
    "LABEL_COL_CANDIDATES = [\"bot\", \"label\", \"target\", \"is_bot\"]\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2c028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (50000, 11)\n",
      "Columns: ['User ID', 'Username', 'Tweet', 'Retweet Count', 'Mention Count', 'Follower Count', 'Verified', 'Bot Label', 'Location', 'Created At', 'Hashtags']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Mention Count</th>\n",
       "      <th>Follower Count</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Bot Label</th>\n",
       "      <th>Location</th>\n",
       "      <th>Created At</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132131</td>\n",
       "      <td>flong</td>\n",
       "      <td>Station activity person against natural majori...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>2353</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Adkinston</td>\n",
       "      <td>2020-05-11 15:29:50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289683</td>\n",
       "      <td>hinesstephanie</td>\n",
       "      <td>Authority research natural life material staff...</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>9617</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Sanderston</td>\n",
       "      <td>2022-11-26 05:18:10</td>\n",
       "      <td>both live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>779715</td>\n",
       "      <td>roberttran</td>\n",
       "      <td>Manage whose quickly especially foot none to g...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4363</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Harrisonfurt</td>\n",
       "      <td>2022-08-08 03:16:54</td>\n",
       "      <td>phone ahead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>696168</td>\n",
       "      <td>pmason</td>\n",
       "      <td>Just cover eight opportunity strong policy which.</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>2242</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Martinezberg</td>\n",
       "      <td>2021-08-14 22:27:05</td>\n",
       "      <td>ever quickly new I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704441</td>\n",
       "      <td>noah87</td>\n",
       "      <td>Animal sign six data good or.</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>8438</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Camachoville</td>\n",
       "      <td>2020-04-13 21:24:21</td>\n",
       "      <td>foreign mention</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID        Username                                              Tweet  \\\n",
       "0   132131           flong  Station activity person against natural majori...   \n",
       "1   289683  hinesstephanie  Authority research natural life material staff...   \n",
       "2   779715      roberttran  Manage whose quickly especially foot none to g...   \n",
       "3   696168          pmason  Just cover eight opportunity strong policy which.   \n",
       "4   704441          noah87                      Animal sign six data good or.   \n",
       "\n",
       "   Retweet Count  Mention Count  Follower Count  Verified  Bot Label  \\\n",
       "0             85              1            2353     False          1   \n",
       "1             55              5            9617      True          0   \n",
       "2              6              2            4363      True          0   \n",
       "3             54              5            2242      True          1   \n",
       "4             26              3            8438     False          1   \n",
       "\n",
       "       Location           Created At            Hashtags  \n",
       "0     Adkinston  2020-05-11 15:29:50                 NaN  \n",
       "1    Sanderston  2022-11-26 05:18:10           both live  \n",
       "2  Harrisonfurt  2022-08-08 03:16:54         phone ahead  \n",
       "3  Martinezberg  2021-08-14 22:27:05  ever quickly new I  \n",
       "4  Camachoville  2020-04-13 21:24:21     foreign mention  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "150ffc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TEXT_COL=Tweet, LABEL_COL=Bot Label\n"
     ]
    }
   ],
   "source": [
    "def pick_column(candidates, available_cols):\n",
    "    for c in candidates:\n",
    "        if c in available_cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "TEXT_COL = \"Tweet\"\n",
    "LABEL_COL = \"Bot Label\"\n",
    "\n",
    "if TEXT_COL is None or LABEL_COL is None:\n",
    "    raise ValueError(\n",
    "        f\"Could not auto-detect text/label columns.\\n\"\n",
    "        f\"Available columns: {df.columns.tolist()}\\n\"\n",
    "        f\"Please set TEXT_COL and LABEL_COL manually.\"\n",
    "    )\n",
    "\n",
    "print(f\"Using TEXT_COL={TEXT_COL}, LABEL_COL={LABEL_COL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34bd1037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: [0, 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Station activity person against natural majori...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Authority research natural life material staff...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manage whose quickly especially foot none to g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just cover eight opportunity strong policy which.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal sign six data good or.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  Station activity person against natural majori...       1\n",
       "1  Authority research natural life material staff...       0\n",
       "2  Manage whose quickly especially foot none to g...       0\n",
       "3  Just cover eight opportunity strong policy which.       1\n",
       "4                      Animal sign six data good or.       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "1    25018\n",
      "0    24982\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Keep only rows with non-null text/label\n",
    "df = df[[TEXT_COL, LABEL_COL]].dropna().copy()\n",
    "\n",
    "# Convert text to string\n",
    "df[TEXT_COL] = df[TEXT_COL].astype(str)\n",
    "\n",
    "# Convert label to int (works for bool / 0/1 / \"0\"/\"1\")\n",
    "df[LABEL_COL] = df[LABEL_COL].astype(int)\n",
    "\n",
    "# Optional sanity check\n",
    "unique_labels = sorted(df[LABEL_COL].unique().tolist())\n",
    "print(\"Unique labels:\", unique_labels)\n",
    "\n",
    "if not set(unique_labels).issubset({0, 1}):\n",
    "    raise ValueError(f\"Expected binary labels 0/1, got {unique_labels}\")\n",
    "\n",
    "df = df.rename(columns={TEXT_COL: \"text\", LABEL_COL: \"labels\"})\n",
    "\n",
    "display(df.head(5))\n",
    "print(df[\"labels\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ef3941c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'labels'],\n",
      "    num_rows: 40000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'labels'],\n",
      "    num_rows: 5000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'labels'],\n",
      "    num_rows: 5000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df, preserve_index=False)\n",
    "\n",
    "# 80/20 split -> train/temp\n",
    "split1 = dataset.train_test_split(test_size=0.2, seed=SEED)\n",
    "train_ds = split1[\"train\"]\n",
    "temp_ds = split1[\"test\"]\n",
    "\n",
    "# temp split into val/test -> 10/10 total\n",
    "split2 = temp_ds.train_test_split(test_size=0.5, seed=SEED)\n",
    "val_ds = split2[\"train\"]\n",
    "test_ds = split2[\"test\"]\n",
    "\n",
    "print(train_ds)\n",
    "print(val_ds)\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "060876cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3b05c15e564027a797b9657d2443bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3f8b4b1548454c86a43e9240bc2033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb6a5ed1d654c3c862a2318eb88bda8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "    )\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True)\n",
    "val_ds = val_ds.map(tokenize_fn, batched=True)\n",
    "test_ds = test_ds.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acfc957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 40000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "keep_cols = {\"input_ids\", \"attention_mask\", \"labels\"}\n",
    "\n",
    "def keep_only(ds_split):\n",
    "    remove_cols = [c for c in ds_split.column_names if c not in keep_cols]\n",
    "    return ds_split.remove_columns(remove_cols)\n",
    "\n",
    "train_ds = keep_only(train_ds)\n",
    "val_ds = keep_only(val_ds)\n",
    "test_ds = keep_only(test_ds)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "792135e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e8d6f7dc1c4a37a2c60f70b9f8235f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: bert-base-uncased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "classifier.bias                            | MISSING    | \n",
      "classifier.weight                          | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91b1e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=labels, average=\"binary\")[\"precision\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=labels, average=\"binary\")[\"recall\"],\n",
    "        \"f1\": f1.compute(predictions=preds, references=labels, average=\"binary\")[\"f1\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4705726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"ml/bert_v1/checkpoints\", exist_ok=True)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"ml/bert_v1/checkpoints\",\n",
    "    eval_strategy=\"epoch\",          # if error, use evaluation_strategy=\"epoch\"\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,             # v1 short run\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    fp16=False,                     # set True on supported NVIDIA GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ba2a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    processing_class=tokenizer,   \n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04dce037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation metrics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='314' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.6953549981117249\n",
      "eval_model_preparation_time: 0.0026\n",
      "eval_accuracy: 0.4964\n",
      "eval_precision: 0.495208379763762\n",
      "eval_recall: 0.8977777777777778\n",
      "eval_f1: 0.638322321172077\n",
      "eval_runtime: 6.6387\n",
      "eval_samples_per_second: 753.161\n",
      "eval_steps_per_second: 23.649\n",
      "\n",
      "Test metrics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.6955486536026001\n",
      "eval_model_preparation_time: 0.0026\n",
      "eval_accuracy: 0.4934\n",
      "eval_precision: 0.49337525263867055\n",
      "eval_recall: 0.8880355699272433\n",
      "eval_f1: 0.6343294355420817\n",
      "eval_runtime: 6.3534\n",
      "eval_samples_per_second: 786.982\n",
      "eval_steps_per_second: 24.711\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nValidation metrics:\")\n",
    "val_metrics = trainer.evaluate(eval_dataset=val_ds)\n",
    "for k, v in val_metrics.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "print(\"\\nTest metrics:\")\n",
    "test_metrics = trainer.evaluate(eval_dataset=test_ds)\n",
    "for k, v in test_metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a33fd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd70c0f0faa4b86972a6fcfd2487389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to ml/bert_v1/model\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = \"ml/bert_v1/model\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "trainer.save_model(SAVE_DIR)\n",
    "tokenizer.save_pretrained(SAVE_DIR)\n",
    "\n",
    "print(f\"Saved model to {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6235717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01fe14affa845f1899e5d444da63458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'label': 'bot',\n",
       " 'confidence': 0.5287707448005676,\n",
       " 'prob_human': 0.47122928500175476,\n",
       " 'prob_bot': 0.5287707448005676}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "LABELS = {0: \"human\", 1: \"bot\"}  # check if your dataset uses reversed labels\n",
    "\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"ml/bert_v1/model\")\n",
    "mdl = AutoModelForSequenceClassification.from_pretrained(\"ml/bert_v1/model\").to(device)\n",
    "mdl.eval()\n",
    "\n",
    "def predict_text(text):\n",
    "    inputs = tok(text, truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = mdl(**inputs).logits\n",
    "        probs = torch.softmax(logits, dim=-1).squeeze().cpu().tolist()\n",
    "    pred = int(np.argmax(probs))\n",
    "    return {\n",
    "        \"label\": LABELS[pred],\n",
    "        \"confidence\": float(probs[pred]),\n",
    "        \"prob_human\": float(probs[0]),\n",
    "        \"prob_bot\": float(probs[1]),\n",
    "    }\n",
    "\n",
    "predict_text(\"This is a sample tweet for testing the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a14d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a basic model of bert. Lat we can test other models to find the best one. We can also do hyperparameter tuning and try to improve the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
